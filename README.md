# LSTM-toxic-comment-detection
The goal of this project is to develop and train a long-short term memory neural network to detect toxic internet comments.

The dataset used in this task was taken from the Toxic Comment Classification Challenge by Jigsaw.

To achieve the goal, the following steps were taken:
1. General preprocessing:

    a. Generalizing the data for binary classification task
    
    b. Data visualization
   
3. Preprocessing for LSTM:

    a. Removing stop words

    b. Lemmatization

    c. Tokenization

    d. Vocabulary creation

4. Building an LSTM model with Pytorch

The project is still in progress, and the full results are yet to be seen.

Warning: Due to working with explicit data, the project contains elements that some may find offensive and obscene.
